{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "velvet-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course DSC 650 - Data Mining\n",
    "# Name - Vikas Ranjan\n",
    "# Assignment - Assignment 8 - Kafka Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considered-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "from kafka import KafkaProducer, KafkaAdminClient\n",
    "from kafka.admin.new_topic import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-narrow",
   "metadata": {},
   "source": [
    "### Configuration Parameters \n",
    "\n",
    "> **TODO:** Change the configuration prameters to the appropriate values for your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "identified-bonus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_servers': ['kafka.kafka.svc.cluster.local:9092'],\n",
       " 'first_name': 'Vikas',\n",
       " 'last_name': 'Ranjan',\n",
       " 'client_id': 'RanjanVikas',\n",
       " 'topic_prefix': 'RanjanVikas'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    bootstrap_servers=['kafka.kafka.svc.cluster.local:9092'],\n",
    "    first_name='Vikas',\n",
    "    last_name='Ranjan'\n",
    ")\n",
    "\n",
    "config['client_id'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "config['topic_prefix'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-balloon",
   "metadata": {},
   "source": [
    "### Create Topic Utility Function\n",
    "\n",
    "The `create_kafka_topic` helps create a Kafka topic based on your configuration settings.  For instance, if your first name is *John* and your last name is *Doe*, `create_kafka_topic('locations')` will create a topic with the name `DoeJohn-locations`.  The function will not create the topic if it already exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forced-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadParquet(parq_path):\n",
    "    pqr = spark.read.parquet(parq_path)\n",
    "    # Convert from spark dataframe to pandas dataframe\n",
    "    pqr = pqr.toPandas()\n",
    "    return pqr\n",
    "\n",
    "def splitstr(std):\n",
    "    before, after = str(std).split('.')\n",
    "    return before, after\n",
    "\n",
    "def startTimer(results_dir):\n",
    "    # Loop on time\n",
    "    print(\"call function here\")\n",
    "    retval = startTimedParquetStreamUpdateLoop(results_dir)\n",
    "    # Stop if time is over and there are no more partitions.\n",
    "    if ((time.time() - start_time) < 70 and retval == 0):\n",
    "        t = threading.Timer(interval, startTimer(results_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "capable-tradition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic \"RanjanVikas-locations\"\n"
     ]
    }
   ],
   "source": [
    "def create_kafka_topic(topic_name, config=config, num_partitions=1, replication_factor=1):\n",
    "    bootstrap_servers = config['bootstrap_servers']\n",
    "    client_id = config['client_id']\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    name = '{}-{}'.format(topic_prefix, topic_name)\n",
    "    \n",
    "    admin_client = KafkaAdminClient(\n",
    "        bootstrap_servers=bootstrap_servers, \n",
    "        client_id=client_id\n",
    "    )\n",
    "    \n",
    "    topic = NewTopic(\n",
    "        name=name,\n",
    "        num_partitions=num_partitions,\n",
    "        replication_factor=replication_factor\n",
    "    )\n",
    "\n",
    "    topic_list = [topic]\n",
    "    try:\n",
    "        admin_client.create_topics(new_topics=topic_list)\n",
    "        print('Created topic \"{}\"'.format(name))\n",
    "    except TopicAlreadyExistsError as e:\n",
    "        print('Topic \"{}\" already exists'.format(name))\n",
    "    \n",
    "create_kafka_topic('locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-penetration",
   "metadata": {},
   "source": [
    "### Kafka Producer\n",
    "\n",
    "The following code creates a `KafkaProducer` object which you can use to send Python objects that are serialized as JSON.\n",
    "\n",
    "**Note:** This producer serializes Python objects as JSON. This means that object must be JSON serializable.  As an example, Python `DateTime` values are not JSON serializable and must be converted to a string (e.g. ISO 8601) or a numeric value (e.g. a Unix timestamp) before being sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decimal-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    "  bootstrap_servers=config['bootstrap_servers'],\n",
    "  value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "patent-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_send_success(record_metadata):\n",
    "    print('Message sent:\\n    Topic: \"{}\"\\n    Partition: {}\\n    Offset: {}'.format(\n",
    "        record_metadata.topic,\n",
    "        record_metadata.partition,\n",
    "        record_metadata.offset\n",
    "    ))\n",
    "    \n",
    "def on_send_error(excp):\n",
    "    print('I am an errback', exc_info=excp)\n",
    "    # handle exception\n",
    "\n",
    "def send_data(topic, data, config=config, producer=producer, msg_key=None):\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    topic_name = '{}-{}'.format(topic_prefix, topic)\n",
    "    \n",
    "    if msg_key is not None:\n",
    "        key = msg_key\n",
    "    else:\n",
    "        key = uuid.uuid4().hex\n",
    "    \n",
    "    producer.send(\n",
    "        topic_name, \n",
    "        value=data,\n",
    "        key=key.encode('utf-8')\n",
    "    ).add_callback(on_send_success).add_errback(on_send_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "silent-nancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent:\n",
      "    Topic: \"RanjanVikas-locations\"\n",
      "    Partition: 0\n",
      "    Offset: 0\n"
     ]
    }
   ],
   "source": [
    "example_data = dict(\n",
    "    key1='value1',\n",
    "    key2='value2'\n",
    ")\n",
    "\n",
    "send_data('locations', example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deadly-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent:\n",
      "    Topic: \"RanjanVikas-accelerations\"\n",
      "    Partition: 0\n",
      "    Offset: 0\n"
     ]
    }
   ],
   "source": [
    "example_data = dict(\n",
    "    key1='value1',\n",
    "    key2='value2'\n",
    ")\n",
    "\n",
    "send_data('accelerations', example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-horse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
